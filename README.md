# AI Document Summariser (Local RAG + Flask + Ollama + MongoDB Atlas)

A full-stack, AI-powered **document understanding system** that performs:

- Secure file uploads  
- Text extraction from PDF, PPTX, DOCX, TXT  
- Chunking + embeddings  
- Vector indexing using FAISS  
- Local LLM-based summarisation (Ollama)  
- Document-grounded Q&A (RAG)  
- Per-user summary storage in **MongoDB Atlas**  
- Beautiful animated UI  
- (Future) Cloud storage on AWS S3 with one-time download links  

This project runs fully locally for AI inference while storing user metadata and summaries persistently in the cloud.
## ğŸš€ Core Features

### âœ”ï¸ File Upload System
Supports all major document types. Uses secure form uploads via Flask.

### âœ”ï¸ Text Extraction
Extraction pipeline automatically detects the file type and uses:
- `pdfplumber` for PDFs  
- `python-pptx` for PPTX  
- `python-docx` for DOCX  
- Plain-text fallback  

Includes **page number tagging** (`[page: X]`) for accurate RAG retrieval.

### âœ”ï¸ Chunking + Embeddings
Documents are chunked into optimal sizes (400â€“1000 chars).  
Embeddings are generated using **SentenceTransformer (MiniLM)**.

### âœ”ï¸ FAISS Vector Store
All embeddings are stored in a local FAISS index:
Enables fast retrieval for summarization and Q&A.

### âœ”ï¸ Local LLMs via Ollama
Your system supports **multiple local models**:
- `gemma3:1b`  
- `qwen2:1.5b`  
- `llama3.2:latest`

Advantages:
- No API cost  
- No internet dependency  
- High privacy  

### âœ”ï¸ Accurate RAG Summarisation
A two-stage pipeline:

1. Retrieve relevant chunks  
2. Local LLM generates:
   - Headings  
   - Condensed explanations  
   - A final structured conclusion  

### âœ”ï¸ Document Q&A
Users can query ANY part of the uploaded document.

The system:
1. Retrieves relevant chunks  
2. Passes them to local LLM  
3. Generates grounded answers  
4. Returns **page citations**  

### âœ”ï¸ Modern Animated UI
- CSS glassmorphism  
- Smooth transitions  
- Responsive layout  
- Separate Upload Panel & Ask-Question Panel  
- Clear intermediate statuses: Upload â†’ Index â†’ Summarize  

Screenshot reference:  
`file:///mnt/data/Screenshot 2025-11-25 at 12.35.07.png`

# ğŸ—„ï¸ MongoDB Atlas (Core Component)

MongoDB Atlas is used as the **persistent database layer** of the project.

### What is stored in MongoDB Atlas?

#### 1. User Accounts  
- email  
- password (argon2 hash)  
- verification flag  
- created_at  
- last_login_at  

#### 2. User Uploads  
Metadata such as:
- filename  
- file prefix  
- file path  
- upload timestamp  

#### 3. User Summaries  
Every summary generated is also stored:

- summary text  
- model used  
- chunk count  
- pages referenced  
- timestamp  
- links for download  
- parent upload reference  

This enables users to log in from anywhere and access/download their previous summaries.

MongoDB Atlas is now an **active project component**, not a future enhancement.

# ğŸ§± Architecture Overview

Frontend  â†’  Flask Backend  â†’  RAG Pipeline  â†’  Local LLM (Ollama)
â†“
FAISS Vector DB
â†“
MongoDB Atlas (User + Metadata)

## ğŸ“ Project Structure
pdf_summariser/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ chunking.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ retrieval.py
â”‚   â”œâ”€â”€ templates/index.html
â”‚
â”œâ”€â”€ uploads/       # user files (dev only)
â”œâ”€â”€ outputs/       # FAISS index + summaries (dev only)
â”œâ”€â”€ run.sh
â””â”€â”€ README.md

For production: uploads and outputs will move to S3 (see future enhancements).

# ğŸ” Authentication (Current Design)

Authentication is designed using:

- **MongoDB Atlas** for storage  
- **Argon2 hashing** for passwords  
- **Flask-Login** for session handling  
- **Email verification** (token-based)  
- **Session-based security** for UI users  

This enables multiple users to have their own workspace:
- Personal file uploads  
- Personal summaries  
- Personal Q&A history  

# â˜ï¸ Future Enhancements (AWS S3 Only)

### ğŸš€ 1. Move File Storage to AWS S3
Instead of saving files locally, upload documents and summaries to S3.

Planned S3 structure:
s3://bucket/uploads/<user_id>//
s3://bucket/summaries/<user_id>//summary.txt

### ğŸ” 2. One-Time Download Links (Signed URLs)
- A summary or document can be downloaded **only once**  
- URL expires automatically after N minutes  
- Great for security and bandwidth control  

### ğŸ§½ 3. Auto-Deletion Policies
Using S3 lifecycle rules:
- Delete unused summary files after X days  
- Clean orphaned files automatically  

These enhancements convert the system into a **full AI cloud-integrated summariser**.

# ğŸ Summary

This project is a complete **AI-powered document intelligence system** with:

- Modern animated frontend  
- Flask backend  
- Local LLM summarisation  
- RAG-based Q&A  
- MongoDB Atlas user accounts + summary storage  
- FAISS vector indexing  
- Expandable architecture  

And with S3 integration coming next, it becomes a **cloud-backed AI summariser platform** for
everyday or enterprise use.
